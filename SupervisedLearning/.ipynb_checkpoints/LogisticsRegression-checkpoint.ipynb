{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression\n",
    "\n",
    "- Assumption\n",
    "    - Generalized Linear Models\n",
    "- Estimation (Loss and Optimization Technique)\n",
    "- Hypothesis Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption\n",
    "\n",
    "$y_i$ follows a Bernoulli($p_i$) distribution, where $$log(\\frac{p_i}{1-p_i}) = \\beta^Tx_i$$.\n",
    "\n",
    "#### Generalized Linear Models\n",
    "\n",
    "The real logic is this: if we can model <span style=color:red> every paramter of the distribution of $y_i$ as some parametric function of $x_i$, </span> we can estimate the parameters through MLE on any sample of $(X, Y)$.\n",
    "\n",
    "For distributions in the exponential family, where the pdf takes the form $f_Y(y|\\theta, \\phi, w) = c(y, \\phi, w) e^{\\frac{y\\theta - b(\\theta)}{\\phi}w}$, we have two sets of parameters that can fully characterize them. One is the familiar set, such as $(n,p)$ for binomial, $\\lambda$ for Poisson, or $(\\mu, \\sigma^2)$ for normal; the other set is the $(\\theta, \\phi, b)$ that comes from the unified expression of an exponential family function. \n",
    "\n",
    "In any GLM model, we assume $\\theta$ is a linear combination of $x$, and try to put the familiar set of paramters in terms of $\\theta$, so that all paramters can be eventually stated in terms of $x$. This link between familiar parameters and exponential family paramters can be found through properties of the above pdf. Specifically <span style=color:red> the below system of equations holds</span>:\n",
    "\n",
    "$$\\mu_i = b'(\\theta_i)$$ \n",
    "and \n",
    "$$Var(y_i|x_i) = \\frac{\\phi}{w_i}v(\\mu)$$\n",
    "\n",
    "where the <span style=color:red>__LHS are supposed to be expressed in term of the familiar parameters, and RHS in terms of the exponential family distribution parameters__</span>. $b'$ is called the link function. It maps $\\theta$ to $\\mu$.\n",
    "\n",
    "Why are two equations enough? All distributions in the exponential family have no more than 2 paramters. They include _Binomial, Poisson, Negative Binomial, Gamma, Inverse Gamma, Gaussian_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation\n",
    "\n",
    "#### Loss Function from Likelihood\n",
    "\n",
    "Note the likelihood of one Bernoulli sample is conviniently expressed as $$p_i^{y_i}(1 - p_i)^{1 - y_i}$$\n",
    "\n",
    "Then the negative log likelihood on the sample is nothing but $$J(\\beta) = -\\Sigma_{i}[y_iln(p_i) + (1 - y_i)ln(1 - p_i)]$$ \n",
    "\n",
    "This is also called \"cross-entropy loss\". The optimal $\\beta$ is our estimate.\n",
    "\n",
    "#### Optimization Technique\n",
    "\n",
    "Optimized through Newton-Ralphson's Method. It converges in the order of 2, meaning the error shrinks by about 2 significant digits with each iteration.\n",
    "\n",
    "When used to find root, Newton's method updates through $$x \\leftarrow x - \\frac{f(x)}{f'(x)}$$\n",
    "\n",
    "When used to optimize the loss, we're doing the same thing as finding the root of the Jacobian: $$\\hat{\\beta} \\leftarrow \\hat{\\beta} - (\\nabla^2 J)^{-1} \\nabla J $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing\n",
    "\n",
    "We test $H_0$ against $H_1$ through likelihood ratio test. Note originally \n",
    "$$\\Lambda = \\frac{L(\\hat{\\beta}_{H_0}|H_0)}{L(\\hat{\\beta}_{H_1}|H_1)}$$\n",
    "\n",
    "After applying twice negative log likelihood, we have \n",
    "$$-2ln(\\Lambda) = 2(J(\\hat{\\beta}_{H_0}|H_0) - J(\\hat{\\beta}_{H_1}|H_1))$$.\n",
    "\n",
    "Almost miracously, this statistic follows a $\\chi^2$ with dof equaling difference in number of paramters in two hypothesis. \n",
    "\n",
    "#### Reading off outputs from R\n",
    "\n",
    "In R output, Deviance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
